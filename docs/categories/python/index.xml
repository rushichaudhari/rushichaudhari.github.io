<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on A collection of random ideas so I don&#39;t have to google again</title>
    <link>https://rushichaudhari.github.io/categories/python/</link>
    <description>Recent content in python on A collection of random ideas so I don&#39;t have to google again</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Sep 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://rushichaudhari.github.io/categories/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hudson and Thames mlfinlab stuff</title>
      <link>https://rushichaudhari.github.io/posts/2022-09-29-hudson-and-thames-mlfinlab-docker/</link>
      <pubDate>Thu, 29 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-09-29-hudson-and-thames-mlfinlab-docker/</guid>
      <description>Dockerfile FROM python:3.8-slim-busterRUN apt update &amp;amp;&amp;amp; apt install git -yRUN apt install -y build-essential g++ libgl1-mesa-glx libx11-6 cmake protobuf-compiler -yRUN python -m pip install jupyter cvxpyRUN git clone https://github.com/rushic24/mlfinlab.git &amp;amp;&amp;amp; cd mlfinlab &amp;amp;&amp;amp; python setup.py installRUN pip install pandas==1.5.2 tqdm statsmodels==0.13.5 numpy==1.23.5EXPOSE 8890ENTRYPOINT [ &amp;#34;jupyter&amp;#34;, &amp;#34;notebook&amp;#34;, &amp;#34;--no-browser&amp;#34;, &amp;#34;--port=8890&amp;#34;, &amp;#34;--ip=0.0.0.0&amp;#34;, &amp;#34;--allow-root&amp;#34; ] Makefile # Specify the name of the imageIMAGE_NAME = &amp;#34;mlfinlabstuf&amp;#34;# Specify the path to the DockerfileDOCKERFILE_PATH = &amp;#34;.</description>
    </item>
    
    <item>
      <title>Apache Hadoop Stack: MapReduce, Pig, Spark, Hive</title>
      <link>https://rushichaudhari.github.io/posts/2022-06-19-apache_hadoop_stack_mapreduce_pig_spark_hive/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-06-19-apache_hadoop_stack_mapreduce_pig_spark_hive/</guid>
      <description>Apache Hadoop Stack: MapReduce, Pig, Spark, Hive 1. HDFS CLI: load input data list all directories hadoop fs -ls make a new directory to store movie data hadoop fs -mkdir movieData copy data file from local to hdfs hadoop fs -copyFromLocal u.data movieData/u.data 2. MapReduce with Python: movies sorted by rating counts script from mrjob.job import MRJob from mrjob.step import MRStep class RatingsBreakdown(MRJob): def steps(self): return [ MRStep(mapper=self.mapper_get_movie, combiner=self.combiner_count_ratings, reducer=self.reducer_count_ratings), MRStep(reducer=self.</description>
    </item>
    
    <item>
      <title>Collaborative Filtering on Amazon Products With PySpark</title>
      <link>https://rushichaudhari.github.io/posts/2022-06-19-collaborative-filtering-on-amazon-products-with-pyspark/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-06-19-collaborative-filtering-on-amazon-products-with-pyspark/</guid>
      <description>Goals Recommend top 5 products for an user: RMSE = 1.22 Data set description This is a list of over 34,000 consumer reviews for Amazon products like the Kindle, Fire TV Stick, and more provided by Datafiniti&amp;rsquo;s Product Database. The dataset includes basic product information, rating, review text, and more for each product. Note that this is a sample of a large dataset. The full dataset is available through Datafiniti. from pyspark.</description>
    </item>
    
    <item>
      <title>Golden Hour of Publishing Comments</title>
      <link>https://rushichaudhari.github.io/posts/2022-06-19-golden-hour-of-publishing-comments/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-06-19-golden-hour-of-publishing-comments/</guid>
      <description>Hacker News is a site similar to Reddit where user-submitted stories (known as &amp;ldquo;posts&amp;rdquo;) are voted on and commented on. In the tech and startup worlds, Hacker News is immensely popular, and pieces that reach the top of the site&amp;rsquo;s listings can get hundreds of thousands of views.
We&amp;rsquo;ll compare these two types of posts to determine the following: 1. Do &amp;lsquo;Ask HN&amp;rsquo; or &amp;lsquo;Show HN&amp;rsquo; posts receive more comments on average?</description>
    </item>
    
    <item>
      <title>Modeling and Analysis of One Finger QWERTY Keyboard Typing Using Fiit&#39;s and Zipf&#39;s Laws</title>
      <link>https://rushichaudhari.github.io/posts/2022-06-19-modeling-and-analysis-of-one-finger-qwerty-keyboard-typing-using-fiits-and-zipfs-laws/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-06-19-modeling-and-analysis-of-one-finger-qwerty-keyboard-typing-using-fiits-and-zipfs-laws/</guid>
      <description>Goals 1. Modeling the keyboard 2. Fiit&amp;rsquo;s law parameter estimation: r-squared = 0.709 3. Average typing time of 1000 most frequent words: 0.99 4. Zipf&amp;rsquo;s law parameter estimation &amp;amp; average typing time of 1000 most frequent words: 0.71 import matplotlib.pyplot as plt import math import numpy numpy.set_printoptions(precision=2) import scipy.stats as stats import statsmodels.api as sm from statsmodels.graphics.regressionplots import abline_plot import seaborn as sns 1. Keyboard modeling # Define keyboard line1 = &amp;#39;qwertyuiop&amp;#39; line2 = &amp;#39;asdfghjkl&amp;#39; line3 = &amp;#39;zxcvbnm&amp;#39; # Define a keyboard as a list of keys.</description>
    </item>
    
    <item>
      <title>Why Do We Need an Opensource Face Detection APIs?</title>
      <link>https://rushichaudhari.github.io/posts/2022-05-06-why-do-we-need-an-opensource-face-detection-apis/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-05-06-why-do-we-need-an-opensource-face-detection-apis/</guid>
      <description>A comparison of different Face Detection APIs in the industry Why do we need an opensource face detection APIs ? Consider we have around 80,000 videos which consists of around a total of 72 million frames. Below is an analysis of how different competitor’s face detection APIs would cost for 72 million frames. Some people have a myth that opensource models don’t work that well compared to these premium services. I’ve also shared a few test screenshots on how even premium service give false positives.</description>
    </item>
    
    <item>
      <title>Convert Browser Requests to Python</title>
      <link>https://rushichaudhari.github.io/posts/2022-04-24-convert-browser-requests-to-python/</link>
      <pubDate>Sun, 24 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-04-24-convert-browser-requests-to-python/</guid>
      <description>Scraping dynamic content these days is bit difficult as there are wide variety of authentication mechanisms and web server needs correct headers, session, cookies to authenticate the request. If we need to quickly scrape content just for once, implementing authenticationis an overhead. Instead, we can manually login to the website, capture an authenticated request and use it for scraping other pages by changing url/form parameters.
curl &amp;#39;https://www.glassdoor.com/member/home/index.htm&amp;#39; -H &amp;#39;User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:99.</description>
    </item>
    
    <item>
      <title>Webscraping 1 minute stock data from tradingview</title>
      <link>https://rushichaudhari.github.io/posts/2020-06-28-trading-view-scraping/</link>
      <pubDate>Tue, 22 Dec 2020 01:21:27 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2020-06-28-trading-view-scraping/</guid>
      <description>How I webscraped 1 minute stock data from tradingview After a long die-hard trying I managed to get 1 minute stock data for free. My previous tries were using selenium and beautifulsoup modules in python. But the data is highly obfuscated so I was not able to find the exact HTML element to scrape. If you manage to do this using selenium please comment below.
Probably the data is being loaded up as SVG which is why it isn&amp;rsquo;t being seen in html inspect element.</description>
    </item>
    
    <item>
      <title>LSTMS for stock price predictions, worth it ?</title>
      <link>https://rushichaudhari.github.io/posts/2020-07-03-lstm-stock-prediction-worth-it/</link>
      <pubDate>Fri, 03 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2020-07-03-lstm-stock-prediction-worth-it/</guid>
      <description>The internet is now flooded with “predicting stock market prices using LSTM”. I went through 9 articles that I found on websites like medium, KDnuggets, etc. And I realized almost 6-7 out of them showed promising results. But none of them showed their real-life use-case; the question is is it beneficial?
LSTMS predict T+1th term by previous k terms of time-series, say k=2, So we need to have T and T-1 to predict T+2 so suppose my X for input is Open, High, Low, Close, Volume, and Y would be the next day’s Close</description>
    </item>
    
    <item>
      <title>Automate Google forms without selenium</title>
      <link>https://rushichaudhari.github.io/posts/2020-07-02-automate-forms-without-selenium/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2020-07-02-automate-forms-without-selenium/</guid>
      <description>In the previous year, I had posted a script to fill google forms using selenium, and containerizing it with docker to run it parallelly. This is an alternative way to do the same using post requests.
I had created a google form using the default template shown below.
Which had fields like To get started we need to capture the request. I&amp;rsquo;ve used burp suite tool to capture, there are many alternative tools you can google.</description>
    </item>
    
  </channel>
</rss>
