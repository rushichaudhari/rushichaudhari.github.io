<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on A collection of random ideas so I don&#39;t have to google again</title>
    <link>https://rushichaudhari.github.io/tags/python/</link>
    <description>Recent content in python on A collection of random ideas so I don&#39;t have to google again</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 19 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://rushichaudhari.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Collaborative Filtering on Amazon Products With PySpark</title>
      <link>https://rushichaudhari.github.io/posts/2022-06-19-collaborative-filtering-on-amazon-products-with-pyspark/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-06-19-collaborative-filtering-on-amazon-products-with-pyspark/</guid>
      <description>Goals Recommend top 5 products for an user: RMSE = 1.22 Data set description  This is a list of over 34,000 consumer reviews for Amazon products like the Kindle, Fire TV Stick, and more provided by Datafiniti&amp;rsquo;s Product Database. The dataset includes basic product information, rating, review text, and more for each product. Note that this is a sample of a large dataset. The full dataset is available through Datafiniti.</description>
    </item>
    
    <item>
      <title>Golden Hour of Publishing Comments</title>
      <link>https://rushichaudhari.github.io/posts/2022-06-19-golden-hour-of-publishing-comments/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-06-19-golden-hour-of-publishing-comments/</guid>
      <description>Hacker News is a site similar to Reddit where user-submitted stories (known as &amp;ldquo;posts&amp;rdquo;) are voted on and commented on. In the tech and startup worlds, Hacker News is immensely popular, and pieces that reach the top of the site&amp;rsquo;s listings can get hundreds of thousands of views.
We&amp;rsquo;ll compare these two types of posts to determine the following: 1. Do &amp;lsquo;Ask HN&amp;rsquo; or &amp;lsquo;Show HN&amp;rsquo; posts receive more comments on average?</description>
    </item>
    
    <item>
      <title>Modeling and Analysis of One Finger QWERTY Keyboard Typing Using Fiit&#39;s and Zipf&#39;s Laws</title>
      <link>https://rushichaudhari.github.io/posts/2022-06-19-modeling-and-analysis-of-one-finger-qwerty-keyboard-typing-using-fiits-and-zipfs-laws/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-06-19-modeling-and-analysis-of-one-finger-qwerty-keyboard-typing-using-fiits-and-zipfs-laws/</guid>
      <description>Goals 1. Modeling the keyboard 2. Fiit&amp;rsquo;s law parameter estimation: r-squared = 0.709 3. Average typing time of 1000 most frequent words: 0.99 4. Zipf&amp;rsquo;s law parameter estimation &amp;amp; average typing time of 1000 most frequent words: 0.71 import matplotlib.pyplot as plt import math import numpy numpy.set_printoptions(precision=2) import scipy.stats as stats import statsmodels.api as sm from statsmodels.graphics.regressionplots import abline_plot import seaborn as sns 1. Keyboard modeling # Define keyboard line1 = &amp;#39;qwertyuiop&amp;#39; line2 = &amp;#39;asdfghjkl&amp;#39; line3 = &amp;#39;zxcvbnm&amp;#39; # Define a keyboard as a list of keys.</description>
    </item>
    
    <item>
      <title>Convert Browser Requests to Python</title>
      <link>https://rushichaudhari.github.io/posts/2022-04-24-convert-browser-requests-to-python/</link>
      <pubDate>Sun, 24 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-04-24-convert-browser-requests-to-python/</guid>
      <description>Scraping dynamic content these days is bit difficult as there are wide variety of authentication mechanisms and web server needs correct headers, session, cookies to authenticate the request. If we need to quickly scrape content just for once, implementing authenticationis an overhead. Instead, we can manually login to the website, capture an authenticated request and use it for scraping other pages by changing url/form parameters.
curl &#39;https://www.glassdoor.com/member/home/index.htm&#39; -H &#39;User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:99.</description>
    </item>
    
    <item>
      <title>Lets Clone the Voice of Priyanka Chopra Jonas</title>
      <link>https://rushichaudhari.github.io/posts/2022-01-12-lets-clone-the-voice-of-priyanka-chopra-jonas/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2022-01-12-lets-clone-the-voice-of-priyanka-chopra-jonas/</guid>
      <description>I had decided to get my email reminders using any celebrity&amp;rsquo;s voice in my previous post Alexa AI for reminding important emails and reminders. Here is a small step towards it :D
If you don&amp;rsquo;t know how Priyanka Chopra sounds like, here is a real sample     Sample synthesized voice 1   Sample synthesized voice 2   Sample synthesized voice 3   Real voice of Amitabh Bachchan     Sample synthesized voice for Amitabh Bachchan This one is more robotic.</description>
    </item>
    
    <item>
      <title>Alexa AI for reminding important emails and reminders</title>
      <link>https://rushichaudhari.github.io/posts/2021-12-19-alexa-remind-emails/</link>
      <pubDate>Sun, 19 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2021-12-19-alexa-remind-emails/</guid>
      <description>Motivation :- It was the third time I missed reading my email and picking up shifts for my oncampus job. I did try creating labels and filtering them but that didn&amp;rsquo;t show any progress in improvement. It&amp;rsquo;s really stressful when I get the notification that something needs a response from me right away. I had to make sure that I was not missing this next time. It is then when I decided I need to build a system to process and remind me this.</description>
    </item>
    
    <item>
      <title>Pca VS AutoEncoders</title>
      <link>https://rushichaudhari.github.io/posts/2021-11-25-pca-vs-autoencoders/</link>
      <pubDate>Thu, 25 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>https://rushichaudhari.github.io/posts/2021-11-25-pca-vs-autoencoders/</guid>
      <description>PCA import numpy as np import sklearn import matplotlib.pyplot as plt from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import MinMaxScaler from tensorflow.keras.datasets import fashion_mnist import seaborn as sns import os import gzip import sys # The number of components for pca N_COMP = 100 #@param {type:&amp;#34;integer&amp;#34;} #Load data: (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data() #Design matrix print(&amp;#39;Design matrix size: {}&amp;#39;.format(X_train.shape)) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step 40960/29515 [=========================================] - 0s 0us/step Downloading data from https://storage.</description>
    </item>
    
  </channel>
</rss>
